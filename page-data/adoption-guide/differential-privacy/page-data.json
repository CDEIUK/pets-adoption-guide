{"componentChunkName":"component---node-modules-rocketseat-gatsby-theme-docs-core-src-templates-docs-query-js","path":"/adoption-guide/differential-privacy/","result":{"data":{"mdx":{"id":"6d1570f2-0082-5cbd-94ea-a4afdbe9216a","excerpt":"Based on your responses, you may want to use a differentially private system to derive the insights you wish to share. What is differential privacyâ€¦","fields":{"slug":"/adoption-guide/differential-privacy/"},"frontmatter":{"title":"Differential privacy","description":null,"image":null,"disableTableOfContents":null},"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Differential privacy\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Based on your responses, you may want to use a differentially private system to derive the insights you wish to share.\"), mdx(\"h2\", {\n    \"id\": \"what-is-differential-privacy\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#what-is-differential-privacy\",\n    \"aria-label\": \"what is differential privacy permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"What is differential privacy?\"), mdx(\"p\", null, \"Differential privacy is a formal definition of privacy requiring that the output of any statistical analysis reveals no information specific to an individual in the dataset. An algorithm is typically made differentially private by adding noise to either the input data (local differential privacy) or to the output it produces (global differential privacy).\"), mdx(\"p\", null, \"Differential privacy was developed in response to a 2003 paper by Irit Nisur and Kobbi Nissim which established the fundamental law of information recovery: overly accurate answers to too many queries of a statistical model enables dataset recovery. It follows that in order for the data used to build a model to be private, it must necessarily be inaccurate to some extent. The amount of noise must be chosen carefully: too little and the dataset will not be private, too much and the output will be so inaccurate as to be useless. This is the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"privacy-utility trade-off\")), \".\"), mdx(\"p\", null, \"The privacy-utility trade-off is formalised through the concept of \\u0190-differential privacy. Querying a model leaks information about the dataset, and the amount of information leakage increases with the number of queries. The parameter \\u0190 quantifies this leakage and is known as the privacy budget. A user is stopped from performing further queries if they exceed their budget. Equivalently, \\u0190 can be thought of as the maximum permissible difference between the result of a query performed against a model, and the result of an identical query performed against a model where an individual has been omitted from the dataset.\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"950px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"37.5%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAAB0UlEQVQoz2MoquvlW7Lzit+s9adFGaDg9oWjLPeefSg+cffFtONXHxgyYAFdjccYeyr3M8L4HOzcEEZ5XXvgxfsf/68/dCsuePZt1fSFV0wPvfwvvfvIus+nnv7/v/biq2y9mgv8Bctv2sVMPGmQv/KucP7y2/wMuEBt2yTZ41eetm05dltbv+cWe1jfHr5v//9zr1jSMGvZjPUn1z/64wRSV7bqllDavMvyBctum6VufazcV3XQs7/2aBvIcYyMTDxCApJMQDYTTov+///PDMRs//8vxCrfW30oY0Lt0QUu1nFCQK4CMxOLEpDmY6hq7tU8fPHx8g2HbprbTr7Nk7r4psjOk0/4rj18uGnH1Wcvdl946AsyoGDxFdmYSSeNC1bcsc5ZfU8X6EL7CXXH4oI9i6SA0szpUb2Q8Kxsn65z5NLT/6sP3IgImXtHMWXeBcPz//9Lrt086cORc2/+r7n+KVM95xBv8crbZhnzr8oAw5C7cMktLjTfIDgCYnJ8a3aest53+j4PkgKm9St6IjbMWl+85ekfVWxe7qk9zNRXc5h53zKIYWqKJnA5BVhgFs8/xVS/6wMjRngde82UMP8WY9ai6wz5K+4w5C2/jTPsAc8G1rWc3oWdAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"picture\", {\n    parentName: \"span\"\n  }, \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/8ac56/dp.webp 240w\", \"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/d3be9/dp.webp 480w\", \"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/4a41d/dp.webp 950w\"],\n    \"sizes\": \"(max-width: 950px) 100vw, 950px\",\n    \"type\": \"image/webp\"\n  })), \"\\n        \", mdx(\"source\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"srcSet\": [\"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/8ff5a/dp.png 240w\", \"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/e85cb/dp.png 480w\", \"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/906b5/dp.png 950w\"],\n    \"sizes\": \"(max-width: 950px) 100vw, 950px\",\n    \"type\": \"image/png\"\n  })), \"\\n        \", mdx(\"img\", _extends({\n    parentName: \"picture\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"src\": \"/pets-adoption-guide/static/baf58ef8f5d3acad1956f0ebe27f7169/906b5/dp.png\",\n    \"alt\": \"Differential privacy\",\n    \"title\": \"Differential privacy\",\n    \"loading\": \"lazy\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    }\n  })), \"\\n      \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"why-differential-privacy\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#why-differential-privacy\",\n    \"aria-label\": \"why differential privacy permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Why differential privacy?\"), mdx(\"p\", null, \"Your answers to the questions in the Adoption Guide indicate that:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You hold data that you want to share with a third party\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You don't want to share the raw data, but rather insights derived from the raw data\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The data is such that generalisations can be made over a population\")), mdx(\"p\", null, \"Differential privacy is therefore potentially a suitable solution, as it allows insights derived from the raw data to be shared, whilst providing a mathematical guarantee on the amount of information that can be inferred about any individual row in the dataset.\"), mdx(\"h2\", {\n    \"id\": \"limitations-to-consider\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#limitations-to-consider\",\n    \"aria-label\": \"limitations to consider permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Limitations to consider\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Choosing a suitable valuable for the privacy budget is often challenging and highly context-specific\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Inaccuracies introduced by noise will be more pronounced for smaller sub-populations. For example, \", mdx(OutboundLink, {\n    href: \"https://www.adn.com/nation-world/2021/04/13/16-states-including-alaska-back-alabama-challenge-to-census-bureaus-new-privacy-tool/\",\n    mdxType: \"OutboundLink\"\n  }, \"critics of the US Census Bureau's use of differential privacy\"), \" have argued that it leads to an inaccurate understanding of local demographics, which could lead to communities being adversely affected by policy decisions that are made based on that data.\")), mdx(Collapse, {\n    label: \"Technical resources\",\n    mdxType: \"Collapse\"\n  }, mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), \"Resource\"), mdx(\"th\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), \"Description\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), mdx(OutboundLink, {\n    href: \"https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id/dp-blog\",\n    mdxType: \"OutboundLink\"\n  }, \"NIST's differential privacy blog series\")), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), \"A series of blogs from the US National Institute of Standards and Technology covering use cases and technical aspects of differential privacy.\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), mdx(OutboundLink, {\n    href: \"https://github.com/google/differential-privacy\",\n    mdxType: \"OutboundLink\"\n  }, \"Google's differential privacy libraries\")), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), \"Includes libraries that implement noise addition primitives and differentially private aggregations, and an end-to-end differential privacy framework built on Apache Beam. Libraries are written in Go, C++, and Java, and OpenMined provide a \", mdx(OutboundLink, {\n    href: \"https://github.com/OpenMined/PyDP\",\n    mdxType: \"OutboundLink\"\n  }, \"Python wrapper\"), \".\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), mdx(OutboundLink, {\n    href: \"https://opacus.ai/\",\n    mdxType: \"OutboundLink\"\n  }, \"PyTorch Opacus\")), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), \"Library for training differentially private machine learning models using the PyTorch framework\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), mdx(OutboundLink, {\n    href: \"https://github.com/tensorflow/privacy\",\n    mdxType: \"OutboundLink\"\n  }, \"TensorFlow Privacy\")), mdx(\"td\", _extends({\n    parentName: \"tr\"\n  }, {\n    \"align\": \"left\"\n  }), \"Library for training differentially private machine learning models using the TensorFlow framework\"))))), mdx(Collapse, {\n    label: \"Use Cases\",\n    mdxType: \"Collapse\"\n  }, \"See the full \", mdx(\"a\", {\n    href: \"/repository\"\n  }, \"use case repository\"), \" for additional fields.\", mdx(AdoptionGuideRepositoryTable, {\n    pet: \"dp\",\n    mdxType: \"AdoptionGuideRepositoryTable\"\n  })), mdx(\"p\", null, \"Click \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"/pets-adoption-guide/adoption-guide\"\n  }), \"here\"), \" to return to the Adoption Guide.\"));\n}\n;\nMDXContent.isMDXComponent = true;","headings":[{"depth":2,"value":"What is differential privacy?"},{"depth":2,"value":"Why differential privacy?"},{"depth":2,"value":"Limitations to consider"}]}},"pageContext":{"slug":"/adoption-guide/differential-privacy/","next":{"label":"Home","link":"/"}}}}